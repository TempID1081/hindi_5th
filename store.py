import streamlit as st
from google import genai
from google.genai import types
import pathlib

# --- HARDCODE YOUR API KEY HERE ---
GOOGLE_API_KEY = "AIzaSyAYlgueM3h9Q6z9zJ308keNIj_QzK6e1hY"

# --- Initialize Gemini client ---
client = genai.Client(api_key=GOOGLE_API_KEY)

st.title("5th Hindi Book with Vimala Jha")

# --- Path to all chapter PDFs ---
chapter_paths = {
    "Chapter 1: рдкреНрд░рд╛рдХреГрддрд┐рдХ рджреГрд╢реНрдп": "chapters/chap1.pdf",
    "Chapter 2: рдкрде рдореЗрд░рд╛ рдЖрд▓реЛрдХрд┐рдд рдХрд░ рджреЛ": "chapters/chap2.pdf",
    "Chapter 3: рдЕрд╕рд▓реА рдЧрд╣рдиреЗ": "chapters/chap3.pdf",
    "Chapter 6: рдореЗрд░рд╛ рдмрдЪрдкрди": "chapters/chap6.pdf",
    "Chapter 8: рдЕрдкрдирд╛рдкрди": "chapters/chap8.pdf"
}

# --- Select chapter with full name display ---
selected_chapter = st.selectbox("рдЕрдзреНрдпрд╛рдп рдЪреБрдиреЗрдВ (Select a Chapter)", list(chapter_paths.keys()))
chapter_file_path = pathlib.Path(chapter_paths[selected_chapter])

if chapter_file_path.exists():
    st.success(f"ЁЯУД рдЪрдпрдирд┐рдд рдЕрдзреНрдпрд╛рдп: {selected_chapter}")

    # Upload to Gemini if new chapter or not uploaded before
    if 'uploaded_file_id' not in st.session_state or st.session_state.get("current_chapter") != selected_chapter:
        with st.spinner(f"ЁЯУд {selected_chapter} рдХреЛ Gemini рдХреЛ рднреЗрдЬрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ..."):
            uploaded_file_obj = client.files.upload(file=chapter_file_path)
            st.session_state.uploaded_file_id = uploaded_file_obj
            st.session_state.current_chapter = selected_chapter
            st.success("тЬЕ рдЕрдзреНрдпрд╛рдп рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдЕрдкрд▓реЛрдб рд╣реБрдЖ!")

    # --- Creativity level ---
    temperature = st.slider("Creativity (temperature)", 0.0, 1.0, 0.5, 0.05)

    # --- Question input ---
    prompt = st.text_area("рдкреНрд░рд╢реНрди рдкреВрдЫреЗрдВ (рд╣рд┐рдВрджреА рдореЗрдВ)", height=100)

    if st.button("рдЙрддреНрддрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ") and prompt.strip():
        config = types.GenerateContentConfig(
            temperature=temperature,
            top_k=40,
            top_p=1.0,
            max_output_tokens=2048
        )

        with st.spinner("ЁЯза Gemini рдЙрддреНрддрд░ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реИ..."):
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                config=config,
                contents=[st.session_state.uploaded_file_id, prompt]
            )

        st.markdown("### ЁЯУШ Gemini рдХрд╛ рдЙрддреНрддрд░:")
        st.markdown(response.text)
else:
    st.error("тЭМ рдЪрдпрдирд┐рдд рдЕрдзреНрдпрд╛рдп PDF рдлрд╝рд╛рдЗрд▓ рдореМрдЬреВрдж рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ paths рдЬрд╛рдВрдЪреЗрдВред")
